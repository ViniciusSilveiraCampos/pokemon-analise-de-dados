# -*- coding: utf-8 -*-
"""Pokemon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M2yQhdQmUorb-wl-KxHXW4sMi9rZt2l3
"""

import pandas as pd

pip install 'pokebase==1.3.0'

import pokebase as pb

"""# Extração de dados."""

# Extrair o total de pokemons
num_pokemons = pb.APIResourceList("pokemon")
num_pokemons.count

region_num = pb.APIResourceList("region")

for region in region_num:
  print(region)

# Definindo todas as regiões existentes.
_regioes = {
    (1, 151): ("Kanto", 1),
    (152, 251): ("Johto", 2),
    (252, 386): ("Hoenn", 3),
    (387, 493): ("Sinnoh", 4),
    (494, 649): ("Unova", 5),
    (650, 721): ("Kalos", 6),
    (722, 809): ("Alola", 7),
    (810, 898): ("Galar", 8),
    (899, 1302): ("Paldea", 9)
}
# "Hisui" foi retirado por não ser considerado da franquia original de jogos.

# Testando os valores que vão ser extraidos
charmander = pb.pokemon('charmander')
print(charmander.name)
print(charmander.types[0].type)
print(charmander.height)

for status in charmander.stats:
  # Mostrar os status base do pokemon.
  print(f"{status.stat.name}: {status.base_stat}")

charmander.abilities[0]

"""# Formatação dos dados."""

import tqdm
# Criação de uma barra dinamica.
import os

pokemon_data = []


# Extrair a quantiadade de pokemons das primeiras quatro gerações.
for i in tqdm.tqdm(range(1, 493)):
    pokemon = pb.pokemon(i)  # Obtém o Pokémon pelo ID


    # Coletando informações para analise.
    name = pokemon.name
    height = pokemon.height
    types = str(pokemon.types[0].type)
    hp = next(stat.base_stat for stat in pokemon.stats if stat.stat.name == 'hp')
    attack = next(stat.base_stat for stat in pokemon.stats if stat.stat.name == 'attack')
    defense = next(stat.base_stat for stat in pokemon.stats if stat.stat.name == 'defense')
    sp = next(stat.base_stat for stat in pokemon.stats if stat.stat.name == 'speed')

    # Determinar a região e a geração com base no ID do Pokémon
    region, generation = None, None
    for id_range, (reg, gen) in _regioes.items():
        if id_range[0] <= i <= id_range[1]:
            region = reg
            generation = gen
            break


    pokemon_data.append({
        'ID': i,
        'Name': name,
        'Type': types,
        'Height': height,
        'HP': hp,
        "Speed": sp,
        'Attack': attack,
        'Defense': defense,
        'Region': region,
        'Generation': generation
    })


df = pd.DataFrame(pokemon_data)

df.head()

pd.unique(df.Type.values)

"""# Visualização de graficos"""

import plotly.express as px
import plotly.graph_objects as go

bar_visualization = px.bar(df.Type, x="Type", color='Type', barmode='stack')
bar_visualization

"""## Attack"""

graph = px.box(df, x='Attack', y='Type',points='all', title="Attack Pokemons - Median", color="Type")

graph

fig = px.histogram(df, x='Attack', color='Type')
fig.show()

"""## Defense"""

graph = px.box(df, x='Defense', y='Type',points='all', title="Defense Pokemons - Median", color="Type")

graph

"""## HP"""

graph = px.box(df, x='HP', y='Type',points='all', title="HP Pokemons Type - Median", color="Type")

graph

"""## SPEED"""

graph = px.box(df, x='Speed', y='Type',points='all', title="Speed Pokemons Type - Median", color="Type")

graph

"""## Correlation Attack X Defense X HP X Speed"""

graph = px.scatter_matrix(df, dimensions=["Attack","Defense", "HP", "Speed"], color="Type")

graph.show()

# Pegar uma região em especifico para ver o desempenho.
def specific_region(type_you_want):
    filtered_dfs = []

    for typ in type_you_want:
        filtered_df = df[df['Region'].apply(lambda types: typ in types)]
        filtered_dfs.append(filtered_df)

    result_df = pd.concat(filtered_dfs)
    return result_df

Kanto = specific_region(['Kanto'])

fig = px.scatter(Kanto, y="Attack", trendline="ols", facet_col_wrap=17, color='Type')


# Ajusta o espaçamento entre os subplots
fig.update_xaxes(matches=None)
fig.update_yaxes(matches=None)

fig.show()

"""## By Region"""

bar_visualization = px.bar(df, x="Region", color='Region', barmode='stack', title="Number of pokemon by region")

bar_visualization

df_exploded = df.explode('Type')
type_counts = df_exploded.groupby(['Region', 'Type']).size().reset_index(name='Count')

# Criar o gráfico de barras slide.
fig = px.bar(type_counts, x='Type', y='Count', color='Type',
             animation_frame='Region', animation_group='Type',
             range_y=[0, type_counts['Count'].max()],
             title="Amount type of pokemon by region")

fig.show()

"""# Data modeling"""

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder

import torch.nn.functional as F
import torch
import torch.nn as nn

pip install torchviz

# Visualizar a rede neural
from torchviz import make_dot

np.random.seed(123)
torch.manual_seed(123)
# Definir uma seed faz com que todos os pesos venham dentro de um padrão. Isso torna o resultado replicavel.

def specific_types(type_you_want):
    filtered_dfs = []

    for typ in type_you_want:
        filtered_df = df[df['Type'].apply(lambda types: typ in types)]
        filtered_dfs.append(filtered_df)

    result_df = pd.concat(filtered_dfs)
    return result_df

New_base = specific_types(["fire", "water", "grass"])

New_base.head()

type_class = list(New_base['Type'].values)
pokemon_data_base = New_base.drop(columns=['ID', 'Name', 'Type', 'Region'])

encoder = LabelEncoder()
type_class = encoder.fit_transform(type_class)

np.unique(type_class)

test_predictors, training_predictors, test_class, training_class= train_test_split(pokemon_data_base, type_class, test_size=0.25)
# Separar os tipos dde pokemons e suas configurações para o treinamento na rede neural.

training_predictors = np.array(training_predictors.values, dtype= np.float32)

training_predictors = torch.tensor(training_predictors, dtype = torch.float)
training_class = torch.tensor(training_class, dtype=torch.long)

"""## Model"""

classificador = nn.Sequential(
    nn.Linear(6, 5, bias=True),
    nn.ReLU(),
    nn.Linear(5, 5, bias=True),
    nn.ReLU(),
    nn.Linear(5, 3, bias=True),
    )

criterion = nn.CrossEntropyLoss()
Optimizer = torch.optim.Adam(classificador.parameters(), lr=0.001, weight_decay=0.0001)

print(training_predictors.size())
print(training_class.size())

dataset = torch.utils.data.TensorDataset(training_predictors, training_class)
train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)

"""## Train Model"""

for epoca in tqdm.tqdm(range(200)):
  running_loss = 0.
  running_accuracy = 0

  for data in train_loader:
    inputs, labels = data

    Optimizer.zero_grad()

    outputs = classificador.forward(inputs)
    loss = criterion(outputs, labels)
    loss.backward()

    outputs = F.softmax(outputs)
    top_p, top_class = outputs.topk(k=1, dim= 1)

    equals = top_class == labels.view(*top_class.shape)

    running_accuracy += torch.mean(equals.type(torch.float))
    Optimizer.step()
    running_loss += loss.item()

# Visualizar a rede neural.
dot = make_dot(outputs, params=dict(classificador.named_parameters()))
dot.render("classificador", format="png")
dot

"""## Model Evaluation"""

classificador.eval()

test_predictors = np.array(test_predictors.values, dtype= np.float32)
test_predictors = torch.tensor(test_predictors, dtype=torch.float)

predictor = classificador(test_predictors)

F.softmax(predictor)

predictor =[np.argmax(t) for t in predictor.detach().numpy()]

matriz = confusion_matrix(predictor, test_class)

Hit_Rate = accuracy_score(test_class, predictor)
Hit_Rate

fig = px.imshow(matriz,
                text_auto=True,
                color_continuous_scale="inferno")

fig

"""# Arquivo de requerimentos."""

pip freeze > requirements.txt